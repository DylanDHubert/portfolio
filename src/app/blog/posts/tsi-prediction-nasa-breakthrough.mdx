---
title: "Predicting Solar Energy: My NASA Research with CNN-Informer Architecture"
summary: "My work on Total Solar Irradiance prediction using deep learning approaches at NASA Goddard Space Flight Center."
publishedAt: "2024-12-01"
tag: "NASA Research"
images: ["/images/placeholder/nasa-tsi.jpg", "/images/nasa/comparison.png", "/images/nasa/TSI_graph.png"]
---

# Predicting Solar Energy: My NASA Research with CNN-Informer Architecture

## The Problem: Predicting Earth's Solar Energy Input

I started working on Total Solar Irradiance (TSI) prediction as an undergraduate researcher in my university lab, which was collaborating with NASA Goddard Space Flight Center. The goal was to predict the amount of solar energy reaching Earth (measured in watts per square meter) using images from the Helioseismic and Magnetic Imager (HMI).

We actually worked with TSI perturbation (`TSI - 1362 W/m²`) rather than absolute TSI values, which made the problem more tractable for the model to predict variations around the baseline solar constant.

<div style={{ textAlign: 'center', margin: '20px 0' }}>
  <img src="/images/nasa/TSI_graph.png" alt="TSI perturbation graph showing TSI minus 1362 W/m² over time" style={{ maxWidth: '100%', borderRadius: '8px' }} />
</div>

The lab had already done extensive work and found their best baseline: an Informer model using SSA (Singular Spectrum Analysis) with a window size of 1K, where the decomposed signals were recombined into just 3 components: main, trend, and noise. While this approach captured some temporal patterns, I wondered if we were losing valuable information by artificially limiting the model to only 3 recombined signals.

## Getting Started with Machine Learning

This was my introduction to machine learning. I began by rerunning the original baseline metrics to understand what was happening and get familiar with the dataset. Over the course of a semester working with Dr. Ding, I became comfortable with the data and started experimenting with my own ideas—like not recombining the SSA sub-signals, thinking the model could learn to weight them more effectively.

This was my first real machine learning project, and I was learning PyTorch from scratch. Understanding the fundamentals—train/validation/test splits, learning rates, layer architectures—was challenging but exciting, especially in the pre-LLM era when resources were more limited.

I spent a lot of time experimenting with different architectures, debugging gradient flows, and learning hyperparameter tuning. It was a steep learning curve, but each small improvement felt rewarding.

## The Approach: CNN-Informer Hybrid Architecture

I had two main ideas. First, I thought we could leverage the actual visual content of the HMI images instead of just their statistical summaries—sunspots and other solar features visible in the images directly correlate with solar energy output. Second, I believed the model could learn to weight the SSA sub-signals more effectively than manually recombining them into just 3 components.

I designed a hybrid architecture that combined:
- **Custom CNN**: A lightweight architecture with CNN blocks (ReLU, batch normalization, max pooling) designed to connect efficiently to the Informer
- **Informer**: A transformer-based model for time series forecasting
- **SSA Sub-signals**: Individual components from Singular Spectrum Analysis, passed directly to the Informer without artificial recombination

The CNN used global pooling to reduce the image features to a single `batch_size × num_channels` vector that could be integrated with the Informer's input requirements.

## From University Research to NASA Internship

After the semester of research, I had the opportunity to intern with Dr. Wu, the NASA collaborator and solar physicist. During this internship, I worked on expanding the model to include additional SDO (Solar Dynamics Observatory) channels at different wavelengths, which would provide richer input data.

We successfully implemented the CNN architecture during my internship, but ran into a practical challenge: the multi-channel SDO dataset was terabytes in size, making it impossible to secure the computational resources needed to run comprehensive tests with the additional wavelength channels.

## The Architecture Details

The pipeline worked as follows:

1. **HMI Images** → **Preprocessing** (focusing on sunspots and faculae)
2. **Preprocessed Images** → **CNN** → **Global Pooling** (extracting spatial features)
3. **HMI Images** → **Averaging** → **SSA Decomposition** (creating temporal sub-signals)
4. **CNN Features + SSA Sub-signals** → **Concatenation** → **Informer** → **TSI Prediction**

The approach allowed the model to learn both spatial patterns (sunspots, solar features) and temporal patterns (solar cycles, variations) simultaneously. The CNN captured the visual information that previous approaches had ignored, while the SSA sub-signals provided the full temporal decomposition without artificial recombination into just 3 components.

## Preprocessing: Focusing on Relevant Features

Understanding the physics was important. HMI images show the Sun's surface with a granulated orange texture—these granules aren't noise but convection cells, the normal solar surface. What we needed to capture were areas of **high information density** that affect solar energy output:

- **Sunspots**: Dark spots indicating significant solar magnetic activity
- **Faculae**: Bright regions where magnetic fields are highly active

I developed a preprocessing pipeline using computer vision techniques to **extract regions** of interest:
- **Gaussian blurring** to reduce noise while preserving important features
- **Edge extraction** to identify boundaries of active regions
- **Thresholding** to isolate areas of high information density where sunspots and faculae occur
- **Temporal differencing** by subtracting previous/next images to highlight changes in active areas and remove the general solar background

This preprocessing step improved model performance by focusing the CNN on the most relevant features.

When images contain no regions of high information density (no sunspots or faculae), the preprocessed output would be essentially "blank" - showing only zeros or minimal variation. This is actually valuable information for the model, as it signals that only the overall trends like time of year and position in the solar cycle would affect the TSI output, rather than specific solar features.

<div style={{ textAlign: 'center', margin: '20px 0' }}>
  <img src="/images/nasa/comparison.png" alt="Comparison of original HMI image vs preprocessed image highlighting regions of high information density" style={{ maxWidth: '100%', borderRadius: '8px' }} />
</div>

## Results and Evaluation

We tested the model across three different forecasting scenarios:

**Single Point Fill**: Where the model could see data around a missing point to predict (least meaningful but good for validation)

**Gap Filling**: Model saw data before and after but had to predict across gaps of hundreds or thousands of datapoints

**Forecasting**: Like gap filling but with no "after" data—predicting into the future as far as possible (most challenging and practical)

We measured performance using Mean Squared Error (MSE) as our primary metric. The improvements came from several factors:

1. **Smart Preprocessing**: The computer vision preprocessing pipeline focused the model on sunspots and faculae
2. **Visual Feature Extraction**: The CNN learned to recognize these key solar features
3. **Temporal Decomposition**: Using SSA sub-signals without artificial recombination preserved important frequency components
4. **End-to-End Learning**: The entire pipeline learned to optimize for the final prediction task

## Technical Challenges

Handling the massive HMI images at high frequency was challenging. The HMI instrument captures images at regular intervals, creating a continuous stream of high-resolution data. Processing this efficiently required careful attention to data pipelines and memory management.

The challenge became more significant when we tried to incorporate additional SDO channels. The multi-channel dataset grew to terabytes in size, making it impossible to secure the computational resources needed for comprehensive testing.



## What I Learned

1. **Domain Knowledge Matters**: Understanding the physics of sunspots and faculae was essential for effective preprocessing
2. **Don't Throw Away Information**: The recombination of SSA signals into just 3 components was losing valuable temporal information
3. **Hybrid Architectures Can Work**: Combining CNN spatial features with transformer temporal modeling can be effective
4. **Start Simple**: I began with basic CNN approaches before adding the Informer component
5. **Test Multiple Scenarios**: The three different forecasting tests revealed different aspects of model performance
6. **Preprocessing is Important**: The computer vision preprocessing pipeline was as important as the neural network architecture

## Impact and Limitations

This work contributed to the lab's understanding of solar-terrestrial relationships and improved the accuracy of space weather predictions. The approach has potential applications in other areas where visual and temporal data need to be combined for prediction tasks.

While we successfully implemented the CNN architecture and demonstrated its potential, the computational challenges of working with terabytes of multi-channel SDO data highlighted the infrastructure limitations that often constrain research. This experience taught me the importance of balancing technical goals with practical computational constraints.

## Moving Forward

After this project, I transitioned to working on cloud computing projects. The principles I learned from this work—hybrid architectures, preserving information, and domain-aware modeling—continue to influence my approach to machine learning problems.

This project taught me the importance of working on problems that matter. Predicting solar energy input to Earth has real implications for climate science, space weather forecasting, and our understanding of the Sun-Earth system.

The key insight was that sometimes the most effective solutions come from asking "What information are we unnecessarily throwing away?" rather than trying to make things more complex. 